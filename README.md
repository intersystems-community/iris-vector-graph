# IRIS Vector Graph: High-Performance Biomedical Knowledge Graph

A production-ready IRIS-native system for **graph traversal** + **vector search** + **hybrid retrieval** with exceptional performance powered by **ACORN-1 optimization**.

## üöÄ Performance Highlights

- **21.7x faster** overall processing than standard IRIS
- **476 proteins/second** ingestion rate
- **Sub-millisecond** graph queries (0.25ms average)
- **Vector search: 6ms** with HNSW optimization (1790x improvement)
- **JSON_TABLE confidence filtering: 109ms** for structured queries
- **Production-ready** for large-scale biomedical datasets

## üèóÔ∏è Architecture

**IRIS-integrated** solution with embedded Python:
- **IRIS-native REST** endpoints via `%CSP.REST`
- **Embedded Python** for graph computation and vector search
- **HNSW vector search** optimization (6ms performance achieved)
- **RDF-style graph** storage with JSON_TABLE filtering
- **Hybrid retrieval** via Python APIs (not pure SQL)
- **JSON_TABLE confidence filtering** working in production

## üìÅ What's Included

### Core System
- `sql/` ‚Äî RDF tables, HNSW vector indexes (graph_walk_tvf.sql is experimental/non-functional)
- `python/` ‚Äî Working graph operators and vector search implementations
- `iris/src/` ‚Äî IRIS ObjectScript classes for REST API and Python operations
- `scripts/` ‚Äî Performance testing, data loading, environment setup
- `tests/` ‚Äî Comprehensive test suite (unit, integration, e2e, performance)

### Documentation
- `docs/performance/` ‚Äî Performance analysis and benchmarks
- `docs/setup/` ‚Äî Configuration and deployment guides
- `docs/architecture/` ‚Äî Technical documentation

### Performance Testing
- **Biomedical benchmarks** (STRING proteins, PubMed literature)
- **Large-scale datasets** (10K+ entities, 50K+ relationships)
- **Real-world performance** validation with ACORN-1

## üöÄ Quick Start

### 1. Set Up Development Environment

```bash
# Install UV package manager (fast Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and set up project
git clone <repository-url>
cd iris-vector-graph

# Install dependencies and create virtual environment
uv sync

# Activate virtual environment
source .venv/bin/activate  # Linux/macOS
# or
.venv\Scripts\activate     # Windows
```

### 2. Start IRIS with ACORN-1
```bash
# Start ACORN-1 optimized IRIS
docker-compose -f docker-compose.acorn.yml up -d

# Wait for container to be healthy
docker ps --format "table {{.Names}}\t{{.Status}}"
```

### 3. Load Schema & Data
```sql
-- In IRIS SQL terminal
\i sql/schema.sql
\i sql/operators.sql
\i scripts/sample_data_768.sql
```

### 4. Configure Environment
```bash
cp .env.sample .env
# Edit .env with your IRIS connection details
```

### 5. Run Tests
```bash
# Run comprehensive test suite
uv run python tests/python/run_all_tests.py

# Quick tests (skip performance benchmarks)
uv run python tests/python/run_all_tests.py --quick

# Specific test categories
uv run python tests/python/test_iris_rest_api.py        # REST API tests
uv run python tests/python/test_python_sdk.py          # Python SDK tests
uv run python tests/python/test_networkx_loader.py     # Data loading tests
uv run python tests/python/test_performance_benchmarks.py  # Performance benchmarks
```

### 6. Data Ingestion
```bash
# Load graph data using NetworkX loader
uv run python scripts/ingest/networkx_loader.py load data.tsv --format tsv --node-type protein

# Performance testing with biomedical datasets
uv run python scripts/performance/string_db_scale_test.py --max-proteins 10000 --workers 8
```

## üí° Example Queries

### üîç Vector Similarity Search

**Find proteins similar to BRCA1:**

**REST API:**
```bash
curl -X POST http://localhost:52773/kg/vectorSearch \
  -H "Content-Type: application/json" \
  -d '{
    "vector": [0.1, 0.2, 0.3, ...],  # 768-dimensional embedding
    "k": 10,
    "label": "protein"
  }'
```

**Python SDK:**
```python
import iris
import json
import numpy as np

# Connect to IRIS
conn = iris.connect('localhost', 1973, 'USER', '_SYSTEM', 'SYS')
cursor = conn.cursor()

# Vector similarity search using stored procedure
query_vector = np.random.rand(768).tolist()  # 768D embedding
cursor.execute("CALL kg_KNN_VEC(?, ?, ?)", [
    json.dumps(query_vector),
    10,        # top 10 results
    'Gene'     # filter by Gene entities
])

results = cursor.fetchall()
for entity_id, similarity in results:
    print(f"{entity_id}: {similarity:.3f}")
```

**Direct SQL:**
```sql
-- Vector similarity using native IRIS functions
SELECT TOP 10
    id,
    VECTOR_COSINE(emb, TO_VECTOR('[0.1,0.2,0.3,...]')) as similarity
FROM kg_NodeEmbeddings
ORDER BY similarity DESC;
```

### üï∏Ô∏è Graph Traversal

**Find drug-disease pathways:**

**REST API:**
```bash
curl -X POST http://localhost:52773/kg/metaPath \
  -H "Content-Type: application/json" \
  -d '{
    "srcId": "DRUG:aspirin",
    "predicates": ["targets", "interacts_with", "associated_with"],
    "maxHops": 3,
    "dstLabel": "disease"
  }'
```

**Python SDK:**
```python
# Multi-hop graph traversal
cursor.execute("""
    SELECT e1.s as drug, e2.o_id as protein, e3.o_id as disease
    FROM rdf_edges e1
    JOIN rdf_edges e2 ON e1.o_id = e2.s
    JOIN rdf_edges e3 ON e2.o_id = e3.s
    WHERE e1.s = ?
      AND e1.p = 'targets'
      AND e2.p = 'interacts_with'
      AND e3.p = 'associated_with'
""", ['DRUG:aspirin'])

pathways = cursor.fetchall()
for drug, protein, disease in pathways:
    print(f"{drug} ‚Üí {protein} ‚Üí {disease}")
```

**Direct SQL:**
```sql
-- Find shortest paths between drug and disease
WITH RECURSIVE pathway(source, target, path, hops) AS (
  SELECT s, o_id, CAST(s || ' -> ' || o_id AS VARCHAR(1000)), 1
  FROM rdf_edges
  WHERE s = 'DRUG:aspirin'

  UNION ALL

  SELECT p.source, e.o_id, p.path || ' -> ' || e.o_id, p.hops + 1
  FROM pathway p
  JOIN rdf_edges e ON p.target = e.s
  WHERE p.hops < 4
    AND e.o_id LIKE 'DISEASE:%'
)
SELECT path, hops FROM pathway
WHERE target LIKE 'DISEASE:%'
ORDER BY hops LIMIT 10;
```

### üîÄ Hybrid Search (Vector + Text)

**Find cancer-related proteins using both semantic similarity and keywords:**

**REST API:**
```bash
curl -X POST http://localhost:52773/kg/hybridSearch \
  -H "Content-Type: application/json" \
  -d '{
    "vector": [0.1, 0.2, ...],  # Cancer pathway embedding
    "text": "tumor suppressor DNA repair",
    "k": 15,
    "c": 60
  }'
```

**Python SDK:**
```python
# Hybrid search using RRF fusion of vector and text results
import numpy as np

# Use the stored procedure for hybrid search
query_vector = np.random.rand(768).tolist()  # Replace with actual embedding
cursor.execute("CALL kg_RRF_FUSE(?, ?, ?, ?, ?, ?)", [
    15,                              # k final results
    20,                             # k1 vector results
    20,                             # k2 text results
    60,                             # c parameter for RRF
    json.dumps(query_vector),       # query vector as JSON
    'tumor suppressor DNA repair'   # text query
])

results = cursor.fetchall()
for entity_id, rrf_score, vs_score, bm25_score in results:
    print(f"{entity_id}: RRF={rrf_score:.3f}, Vector={vs_score:.3f}, Text={bm25_score:.3f}")

# Alternative: Manual text search in qualifiers
cursor.execute("""
    SELECT s, qualifiers
    FROM rdf_edges
    WHERE qualifiers LIKE '%tumor%' OR qualifiers LIKE '%suppressor%'
    LIMIT 15
""")
text_results = cursor.fetchall()

for result in text_results:
    print(f"Entity: {result[0]}")
    print(f"  Qualifiers: {result[1]}")
```

### üìä Analytics Queries

**Protein interaction network analysis:**

**Python SDK:**
```python
# Find hub proteins (most connections)
cursor.execute("""
    SELECT s as protein, COUNT(*) as connections
    FROM rdf_edges
    WHERE p = 'interacts_with'
      AND s LIKE 'PROTEIN:%'
    GROUP BY s
    ORDER BY connections DESC
    LIMIT 20
""")

hubs = cursor.fetchall()
print("Top protein interaction hubs:")
for protein, connections in hubs:
    print(f"  {protein}: {connections} interactions")
```

**Direct SQL:**
```sql
-- Network clustering coefficient
SELECT
    node,
    connections,
    triangles,
    CASE WHEN connections > 1
         THEN 2.0 * triangles / (connections * (connections - 1))
         ELSE 0 END as clustering_coefficient
FROM (
    SELECT
        e1.s as node,
        COUNT(DISTINCT e1.o_id) as connections,
        COUNT(DISTINCT e2.o_id) as triangles
    FROM rdf_edges e1
    LEFT JOIN rdf_edges e2 ON e1.o_id = e2.s AND e2.o_id IN (
        SELECT o_id FROM rdf_edges WHERE s = e1.s
    )
    WHERE e1.p = 'interacts_with'
    GROUP BY e1.s
) stats
ORDER BY clustering_coefficient DESC;
```

### üß¨ Biomedical Workflows

**Drug discovery pipeline:**

**Python SDK:**
```python
def find_drug_targets(disease_name):
    """Find potential drug targets for a disease (working pattern)"""

    # 1. Find disease-associated proteins
    cursor.execute("""
        SELECT DISTINCT o_id as protein
        FROM rdf_edges
        WHERE s = ? AND p = 'associated_with'
    """, [f"DISEASE:{disease_name}"])

    disease_proteins = [row[0] for row in cursor.fetchall()]

    # 2. Find drugs targeting these proteins
    targets = []
    for protein in disease_proteins:
        cursor.execute("""
            SELECT s as drug, qualifiers
            FROM rdf_edges
            WHERE o_id = ? AND p = 'targets'
        """, [protein])

        targets.extend(cursor.fetchall())

    return targets

# Usage
cancer_drugs = find_drug_targets('cancer')
print(f"Found {len(cancer_drugs)} potential drug-target relationships")
```

**Literature mining example:**

**Python with NetworkX:**
```python
import networkx as nx

# Export IRIS graph to NetworkX for analysis
G = nx.DiGraph()

cursor.execute("SELECT s, o_id, p FROM rdf_edges WHERE p = 'interacts_with'")
for source, target, relation in cursor.fetchall():
    G.add_edge(source, target, relation=relation)

# Network analysis
centrality = nx.betweenness_centrality(G)
communities = nx.community.greedy_modularity_communities(G)

print(f"Network has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges")
print(f"Found {len(communities)} protein communities")
```

## üìä Performance Benchmarks

### Community Edition vs ACORN-1 Comparison

| Metric | Community Edition | ACORN-1 | Improvement |
|--------|------------------|---------|-------------|
| **Total Time** | 468.6 seconds | 21.6 seconds | **21.7x faster** |
| **Data Ingestion** | 29 proteins/sec | 476 proteins/sec | **16.4x faster** |
| **Index Building** | 122.8 seconds | 0.054 seconds | **2,278x faster** |
| **Graph Queries** | 1.03ms avg | 0.25ms avg | **4.1x faster** |

See `docs/performance/` for detailed analysis.

## üß¨ Biomedical Use Cases

### General Biomedical Data Support
- **Protein interactions** (tested with STRING database)
- **Literature analysis** (PubMed abstracts)
- **Molecular ontologies** (Gene Ontology, ChEBI)
- **Drug-target relationships** (DrugBank, ChEMBL)

### Knowledge Graph Operations
- **Vector similarity** search (768-dimensional embeddings)
- **Graph path** discovery
- **Hybrid retrieval** (vector + text)
- **Real-time queries** on large datasets

## üîß Development

### Testing
```bash
# Comprehensive test suite
uv run python tests/python/run_all_tests.py

# Quick tests (skip performance benchmarks)
uv run python tests/python/run_all_tests.py --quick

# Category-specific tests
uv run python tests/python/run_all_tests.py --category api
uv run python tests/python/run_all_tests.py --category performance
```

### Environment Management
```bash
# Start IRIS test environment
./scripts/setup/setup-test-env.sh

# Stop test environment
./scripts/setup/stop-test-env.sh

# ACORN-1 optimized environment
./scripts/setup/setup_acorn_test.sh
```

### Code Quality
```bash
# Format code
uv run black scripts/ tests/

# Lint code
uv run flake8 scripts/ tests/

# Type checking
uv run mypy scripts/ tests/
```

### Performance Analysis
```bash
# Run STRING database scale test
uv run python scripts/performance/string_db_scale_test.py --max-proteins 50000

# View performance results
cat docs/performance/string_scale_test_report.json
```

## üìö Documentation

- **[Performance Analysis](docs/performance/)** ‚Äî Detailed benchmarks and optimization analysis
- **[Setup Guide](docs/setup/)** ‚Äî ACORN-1 configuration and troubleshooting
- **[Architecture](docs/architecture/)** ‚Äî Technical design and data flow
- **[API Reference](docs/api/)** ‚Äî REST endpoint documentation
- **[Graph Primitives Assessment](docs/GRAPH_PRIMITIVES_IMPLEMENTATION_ASSESSMENT.md)** ‚Äî Implementation analysis against indexing specifications

## üéØ Production Deployment

### Requirements
- **IRIS 2025.3.0+** with Vector Search feature
- **ACORN-1 optimization** for best performance
- **Python 3.8+** for embedded operations
- **Docker** for containerized deployment

### Performance Characteristics
- **Real-time** queries (sub-millisecond graph traversal)
- **Vector search** optimized (6ms with HNSW vs 5.8s Python fallback)
- **Large-scale** data processing (millions of proteins)
- **JSON_TABLE filtering** for structured confidence scoring (109ms)
- **Production-ready** reliability and error handling
- **Scalable** architecture for growing datasets

## üèÜ Key Features

- ‚úÖ **21x performance improvement** with ACORN-1
- ‚úÖ **Production-ready** reliability
- ‚úÖ **Biomedical performance** testing (STRING, PubMed ready)
- ‚úÖ **Comprehensive benchmarks** and analysis
- ‚úÖ **IRIS-native** architecture (no external dependencies)
- ‚úÖ **Vector + graph** hybrid capabilities
- ‚úÖ **Scalable** to millions of entities

---

*Powered by InterSystems IRIS with ACORN-1 optimization for exceptional biomedical research performance.*